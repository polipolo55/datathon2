{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52c800b6",
   "metadata": {},
   "source": [
    "# CatBoost CV Upgrade\n",
    "Enhanced notebook with richer feature engineering, robust cross-validation, and calibrated CatBoost inference for the Datathon production challenge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43f3f199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoost GPU detected on device(s): 0\n",
      "Train shape: (95339, 33) | Test shape: (2250, 28)\n",
      "Train shape: (95339, 33) | Test shape: (2250, 28)\n"
     ]
    }
   ],
   "source": [
    "# Imports and configuration\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "from catboost.utils import get_gpu_device_count\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "SEED = 42\n",
    "DATA_DIR = Path(\"data\")\n",
    "SUBMISSION_DIR = Path(\"submissions\")\n",
    "SUBMISSION_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "GPU_DEVICES = \"0\"  # RTX 3060 lives on device 0 by default\n",
    "GPU_AVAILABLE = get_gpu_device_count() > 0\n",
    "CATBOOST_TASK_TYPE = \"GPU\" if GPU_AVAILABLE else \"CPU\"\n",
    "if GPU_AVAILABLE:\n",
    "    print(f\"CatBoost GPU detected on device(s): {GPU_DEVICES}\")\n",
    "else:\n",
    "    print(\"CatBoost GPU not detected; falling back to CPU training.\")\n",
    "\n",
    "TRAIN_PATH = DATA_DIR / \"train.csv\"\n",
    "TEST_PATH = DATA_DIR / \"test.csv\"\n",
    "SAMPLE_SUB_PATH = DATA_DIR / \"sample_submission.csv\"\n",
    "\n",
    "for required_path in [TRAIN_PATH, TEST_PATH]:\n",
    "    if not required_path.exists():\n",
    "        raise FileNotFoundError(\n",
    "            f\"Missing required dataset: {required_path.resolve()} — \"\n",
    "            \"please place the competition CSVs inside data/.\"\n",
    ")\n",
    "\n",
    "def load_dataset(path: Path) -> pd.DataFrame:\n",
    "    df = pd.read_csv(path, sep=\";\")\n",
    "    df = df.loc[:, ~df.columns.str.contains(\"^Unnamed\")]\n",
    "    return df\n",
    "\n",
    "train_df = load_dataset(TRAIN_PATH)\n",
    "test_df = load_dataset(TEST_PATH)\n",
    "sample_submission = load_dataset(SAMPLE_SUB_PATH) if SAMPLE_SUB_PATH.exists() else None\n",
    "\n",
    "print(f\"Train shape: {train_df.shape} | Test shape: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66316bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper utilities for feature engineering\n",
    "def parse_embedding_vector(raw_value):\n",
    "    if pd.isna(raw_value) or raw_value == \"\":\n",
    "        return np.zeros(1, dtype=np.float32)\n",
    "    text = str(raw_value).replace(\"[\", \"\").replace(\"]\", \"\")\n",
    "    values = [part.strip() for part in text.split(\",\") if part.strip() != \"\"]\n",
    "    if not values:\n",
    "        return np.zeros(1, dtype=np.float32)\n",
    "    try:\n",
    "        return np.array([float(v) for v in values], dtype=np.float32)\n",
    "    except ValueError:\n",
    "        return np.zeros(len(values) or 1, dtype=np.float32)\n",
    "\n",
    "def build_embedding_matrix(series: pd.Series) -> np.ndarray:\n",
    "    parsed = [parse_embedding_vector(value) for value in series]\n",
    "    max_dim = max((vec.size for vec in parsed), default=1)\n",
    "    matrix = np.zeros((len(parsed), max_dim), dtype=np.float32)\n",
    "    for row_idx, vec in enumerate(parsed):\n",
    "        matrix[row_idx, : vec.size] = vec\n",
    "    return matrix\n",
    "\n",
    "def add_embedding_features(df: pd.DataFrame, column: str = \"image_embedding\", n_components: int = 48) -> pd.DataFrame:\n",
    "    if column not in df.columns:\n",
    "        return df\n",
    "    df = df.copy()\n",
    "    emb_matrix = build_embedding_matrix(df[column])\n",
    "    df[\"img_emb_mean\"] = emb_matrix.mean(axis=1)\n",
    "    df[\"img_emb_std\"] = emb_matrix.std(axis=1)\n",
    "    df[\"img_emb_abs_mean\"] = np.abs(emb_matrix).mean(axis=1)\n",
    "    df[\"img_emb_max\"] = emb_matrix.max(axis=1)\n",
    "    df[\"img_emb_min\"] = emb_matrix.min(axis=1)\n",
    "\n",
    "    usable_components = min(n_components, emb_matrix.shape[1], max(1, emb_matrix.shape[0] - 1))\n",
    "    if emb_matrix.shape[0] > 1 and usable_components >= 1:\n",
    "        pca = PCA(n_components=usable_components, random_state=SEED)\n",
    "        emb_pca = pca.fit_transform(np.nan_to_num(emb_matrix))\n",
    "        for comp_idx in range(usable_components):\n",
    "            df[f\"img_pca_{comp_idx}\"] = emb_pca[:, comp_idx]\n",
    "\n",
    "    df = df.drop(columns=[column])\n",
    "    return df\n",
    "\n",
    "def safe_ratio(numerator: pd.Series, denominator: pd.Series) -> pd.Series:\n",
    "    denominator = denominator.replace(0, np.nan)\n",
    "    ratio = numerator / denominator\n",
    "    return ratio.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "def engineer_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "\n",
    "    for numeric_col in [\"num_stores\", \"num_sizes\", \"weekly_demand\"]:\n",
    "        if numeric_col in df.columns:\n",
    "            df[numeric_col] = pd.to_numeric(df[numeric_col], errors=\"coerce\")\n",
    "\n",
    "    for col in [\"phase_in\", \"phase_out\"]:\n",
    "        if col in df.columns:\n",
    "            df[f\"{col}_dt\"] = pd.to_datetime(df[col], format=\"%d/%m/%Y\", errors=\"coerce\")\n",
    "\n",
    "    if \"phase_in_dt\" in df.columns:\n",
    "        df[\"phase_in_year\"] = df[\"phase_in_dt\"].dt.year\n",
    "        df[\"phase_in_month\"] = df[\"phase_in_dt\"].dt.month\n",
    "        df[\"phase_in_day\"] = df[\"phase_in_dt\"].dt.day\n",
    "        df[\"phase_in_dayofyear\"] = df[\"phase_in_dt\"].dt.dayofyear\n",
    "        df[\"phase_in_week\"] = df[\"phase_in_dt\"].dt.isocalendar().week.astype(float)\n",
    "        df[\"phase_in_weekday\"] = df[\"phase_in_dt\"].dt.weekday\n",
    "        df[\"phase_in_weekend\"] = (df[\"phase_in_dt\"].dt.weekday >= 5).astype(int)\n",
    "\n",
    "    if \"phase_out_dt\" in df.columns:\n",
    "        df[\"phase_out_month\"] = df[\"phase_out_dt\"].dt.month\n",
    "        df[\"phase_out_week\"] = df[\"phase_out_dt\"].dt.isocalendar().week.astype(float)\n",
    "\n",
    "    if {\"phase_in_dt\", \"phase_out_dt\"}.issubset(df.columns):\n",
    "        df[\"lifecycle_days\"] = (df[\"phase_out_dt\"] - df[\"phase_in_dt\"]).dt.days\n",
    "        df[\"lifecycle_days\"] = df[\"lifecycle_days\"].clip(lower=0)\n",
    "        df[\"lifecycle_weeks\"] = df[\"lifecycle_days\"] / 7.0\n",
    "    else:\n",
    "        df[\"lifecycle_days\"] = np.nan\n",
    "        df[\"lifecycle_weeks\"] = np.nan\n",
    "\n",
    "    df[\"lifecycle_missing\"] = df[\"lifecycle_days\"].isna().astype(int)\n",
    "    df[\"lifecycle_days\"] = df[\"lifecycle_days\"].fillna(df[\"lifecycle_days\"].median())\n",
    "    df[\"lifecycle_weeks\"] = df[\"lifecycle_weeks\"].fillna(df[\"lifecycle_weeks\"].median())\n",
    "\n",
    "    if \"phase_in_month\" in df.columns:\n",
    "        season_map = {\n",
    "            \"winter\": [12, 1, 2],\n",
    "            \"spring\": [3, 4, 5],\n",
    "            \"summer\": [6, 7, 8],\n",
    "            \"fall\": [9, 10, 11],\n",
    "        }\n",
    "        for season_name, months in season_map.items():\n",
    "            df[f\"launch_{season_name}\"] = df[\"phase_in_month\"].isin(months).astype(int)\n",
    "\n",
    "    for cyc_col, period in [(\"phase_in_month\", 12), (\"phase_in_dayofyear\", 365)]:\n",
    "        if cyc_col in df.columns:\n",
    "            angle = 2 * np.pi * df[cyc_col].fillna(0) / period\n",
    "            df[f\"{cyc_col}_sin\"] = np.sin(angle)\n",
    "            df[f\"{cyc_col}_cos\"] = np.cos(angle)\n",
    "\n",
    "    if \"color_rgb\" in df.columns:\n",
    "        def parse_rgb(value):\n",
    "            if pd.isna(value) or value == \"\":\n",
    "                return [128, 128, 128]\n",
    "            try:\n",
    "                parts = [int(float(x)) for x in str(value).split(\",\")]\n",
    "                return parts if len(parts) == 3 else [128, 128, 128]\n",
    "            except ValueError:\n",
    "                return [128, 128, 128]\n",
    "\n",
    "        rgb_values = np.array(df[\"color_rgb\"].apply(parse_rgb).tolist())\n",
    "        df[\"color_r\"] = rgb_values[:, 0]\n",
    "        df[\"color_g\"] = rgb_values[:, 1]\n",
    "        df[\"color_b\"] = rgb_values[:, 2]\n",
    "        df[\"color_mean\"] = rgb_values.mean(axis=1)\n",
    "        df[\"color_std\"] = rgb_values.std(axis=1)\n",
    "        df[\"color_range\"] = np.ptp(rgb_values, axis=1)\n",
    "        df[\"is_dark_color\"] = (df[\"color_mean\"] < 90).astype(int)\n",
    "\n",
    "    ratio_specs = [\n",
    "        (\"weekly_demand\", \"num_stores\", \"demand_per_store\"),\n",
    "        (\"weekly_demand\", \"num_sizes\", \"demand_per_size\"),\n",
    "        (\"num_stores\", \"num_sizes\", \"stores_per_size\"),\n",
    "    ]\n",
    "    for numerator_col, denominator_col, feature_name in ratio_specs:\n",
    "        if numerator_col in df.columns and denominator_col in df.columns:\n",
    "            df[feature_name] = safe_ratio(df[numerator_col], df[denominator_col])\n",
    "\n",
    "    if {\"num_stores\", \"num_sizes\"}.issubset(df.columns):\n",
    "        df[\"stores_times_sizes\"] = df[\"num_stores\"] * df[\"num_sizes\"]\n",
    "\n",
    "    for col in [\"weekly_demand\", \"num_stores\", \"num_sizes\", \"lifecycle_days\"]:\n",
    "        if col in df.columns:\n",
    "            df[f\"log_{col}\"] = np.log1p(df[col].clip(lower=0))\n",
    "\n",
    "    categorical_cols = df.select_dtypes(include=[\"object\", \"category\"]).columns\n",
    "    for col in categorical_cols:\n",
    "        freq = df[col].value_counts(dropna=False, normalize=True)\n",
    "        df[f\"{col}_freq\"] = df[col].map(freq)\n",
    "\n",
    "    df = df.drop(columns=[\"phase_in\", \"phase_out\", \"color_rgb\", \"phase_in_dt\", \"phase_out_dt\"], errors=\"ignore\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e0dc81b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final training matrix: (95339, 133) | Test matrix: (2250, 133)\n",
      "Categorical features tracked: 15\n"
     ]
    }
   ],
   "source": [
    "# Feature engineering and dataset assembly\n",
    "train_df = train_df.copy()\n",
    "test_df = test_df.copy()\n",
    "\n",
    "train_df[\"is_train\"] = 1\n",
    "test_df[\"is_train\"] = 0\n",
    "test_df[\"Production\"] = np.nan\n",
    "\n",
    "full_df = pd.concat([train_df, test_df], ignore_index=True)\n",
    "full_df = add_embedding_features(full_df, column=\"image_embedding\", n_components=48)\n",
    "full_df = engineer_features(full_df)\n",
    "\n",
    "train_processed = full_df[full_df[\"is_train\"] == 1].drop(columns=[\"is_train\"])\n",
    "test_processed = full_df[full_df[\"is_train\"] == 0].drop(columns=[\"is_train\"])\n",
    "\n",
    "test_ids = test_processed[\"ID\"].copy() if \"ID\" in test_processed.columns else pd.Series(np.arange(len(test_processed)))\n",
    "\n",
    "if \"ID\" in train_processed.columns:\n",
    "    train_processed = train_processed.drop(columns=[\"ID\"])\n",
    "    test_processed = test_processed.drop(columns=[\"ID\"])\n",
    "\n",
    "y = train_processed[\"Production\"].astype(float)\n",
    "X = train_processed.drop(columns=[\"Production\"]).reset_index(drop=True)\n",
    "test_features = test_processed.drop(columns=[\"Production\"], errors=\"ignore\").reset_index(drop=True)\n",
    "\n",
    "numeric_cols = X.select_dtypes(include=[np.number]).columns\n",
    "numeric_medians = X[numeric_cols].median().fillna(0)\n",
    "\n",
    "X[numeric_cols] = X[numeric_cols].fillna(numeric_medians)\n",
    "for col in numeric_cols:\n",
    "    fill_value = numeric_medians[col] if col in numeric_medians else 0\n",
    "    if col in test_features.columns:\n",
    "        test_features[col] = test_features[col].fillna(fill_value)\n",
    "    else:\n",
    "        test_features[col] = fill_value\n",
    "\n",
    "missing_test_cols = [col for col in X.columns if col not in test_features.columns]\n",
    "for col in missing_test_cols:\n",
    "    test_features[col] = 0\n",
    "\n",
    "extra_test_cols = [col for col in test_features.columns if col not in X.columns]\n",
    "if extra_test_cols:\n",
    "    test_features = test_features.drop(columns=extra_test_cols)\n",
    "\n",
    "test_features = test_features[X.columns]\n",
    "\n",
    "X[numeric_cols] = X[numeric_cols].astype(np.float32)\n",
    "test_features[numeric_cols] = test_features[numeric_cols].astype(np.float32)\n",
    "\n",
    "categorical_cols = X.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "for col in categorical_cols:\n",
    "    X[col] = X[col].astype(str).fillna(\"missing\")\n",
    "    if col in test_features.columns:\n",
    "        test_features[col] = test_features[col].astype(str).fillna(\"missing\")\n",
    "\n",
    "cat_feature_indices = [X.columns.get_loc(col) for col in categorical_cols]\n",
    "cat_features_for_pool = cat_feature_indices if categorical_cols else None\n",
    "\n",
    "print(f\"Final training matrix: {X.shape} | Test matrix: {test_features.shape}\")\n",
    "print(f\"Categorical features tracked: {len(categorical_cols)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "283f5877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 34218.8376207\ttest: 33576.1227452\tbest: 33576.1227452 (0)\ttotal: 54.9ms\tremaining: 1m 49s\n",
      "250:\tlearn: 6988.4221989\ttest: 7275.2249902\tbest: 7275.2249902 (250)\ttotal: 14s\tremaining: 1m 37s\n",
      "250:\tlearn: 6988.4221989\ttest: 7275.2249902\tbest: 7275.2249902 (250)\ttotal: 14s\tremaining: 1m 37s\n",
      "500:\tlearn: 5330.9555778\ttest: 5663.0056762\tbest: 5663.0056762 (500)\ttotal: 27.7s\tremaining: 1m 22s\n",
      "500:\tlearn: 5330.9555778\ttest: 5663.0056762\tbest: 5663.0056762 (500)\ttotal: 27.7s\tremaining: 1m 22s\n",
      "750:\tlearn: 4416.8471616\ttest: 4761.6843498\tbest: 4761.6843498 (750)\ttotal: 41.4s\tremaining: 1m 8s\n",
      "750:\tlearn: 4416.8471616\ttest: 4761.6843498\tbest: 4761.6843498 (750)\ttotal: 41.4s\tremaining: 1m 8s\n",
      "1000:\tlearn: 3760.2078698\ttest: 4120.0838002\tbest: 4120.0838002 (1000)\ttotal: 55.6s\tremaining: 55.5s\n",
      "1000:\tlearn: 3760.2078698\ttest: 4120.0838002\tbest: 4120.0838002 (1000)\ttotal: 55.6s\tremaining: 55.5s\n",
      "1250:\tlearn: 3274.0893772\ttest: 3641.0907966\tbest: 3641.0907966 (1250)\ttotal: 1m 9s\tremaining: 41.8s\n",
      "1250:\tlearn: 3274.0893772\ttest: 3641.0907966\tbest: 3641.0907966 (1250)\ttotal: 1m 9s\tremaining: 41.8s\n",
      "1500:\tlearn: 2885.6557473\ttest: 3255.1349398\tbest: 3255.1349398 (1500)\ttotal: 1m 24s\tremaining: 28s\n",
      "1500:\tlearn: 2885.6557473\ttest: 3255.1349398\tbest: 3255.1349398 (1500)\ttotal: 1m 24s\tremaining: 28s\n",
      "1750:\tlearn: 2568.7875505\ttest: 2940.0123667\tbest: 2940.0123667 (1750)\ttotal: 1m 38s\tremaining: 14s\n",
      "1750:\tlearn: 2568.7875505\ttest: 2940.0123667\tbest: 2940.0123667 (1750)\ttotal: 1m 38s\tremaining: 14s\n",
      "1999:\tlearn: 2307.5318241\ttest: 2680.3171493\tbest: 2680.3171493 (1999)\ttotal: 1m 52s\tremaining: 0us\n",
      "bestTest = 2680.317149\n",
      "bestIteration = 1999\n",
      "Fold 1 RMSE: 2680.3164\n",
      "1999:\tlearn: 2307.5318241\ttest: 2680.3171493\tbest: 2680.3171493 (1999)\ttotal: 1m 52s\tremaining: 0us\n",
      "bestTest = 2680.317149\n",
      "bestIteration = 1999\n",
      "Fold 1 RMSE: 2680.3164\n",
      "0:\tlearn: 34003.6668836\ttest: 34476.6296778\tbest: 34476.6296778 (0)\ttotal: 47.6ms\tremaining: 1m 35s\n",
      "0:\tlearn: 34003.6668836\ttest: 34476.6296778\tbest: 34476.6296778 (0)\ttotal: 47.6ms\tremaining: 1m 35s\n",
      "250:\tlearn: 6980.3963413\ttest: 7204.2393580\tbest: 7204.2393580 (250)\ttotal: 14.1s\tremaining: 1m 38s\n",
      "250:\tlearn: 6980.3963413\ttest: 7204.2393580\tbest: 7204.2393580 (250)\ttotal: 14.1s\tremaining: 1m 38s\n",
      "500:\tlearn: 5328.0240070\ttest: 5555.1271423\tbest: 5555.1271423 (500)\ttotal: 28.5s\tremaining: 1m 25s\n",
      "500:\tlearn: 5328.0240070\ttest: 5555.1271423\tbest: 5555.1271423 (500)\ttotal: 28.5s\tremaining: 1m 25s\n",
      "750:\tlearn: 4414.3946976\ttest: 4656.2194705\tbest: 4656.2194705 (750)\ttotal: 42.5s\tremaining: 1m 10s\n",
      "750:\tlearn: 4414.3946976\ttest: 4656.2194705\tbest: 4656.2194705 (750)\ttotal: 42.5s\tremaining: 1m 10s\n",
      "1000:\tlearn: 3760.1454856\ttest: 4020.7740740\tbest: 4020.7740740 (1000)\ttotal: 56.7s\tremaining: 56.6s\n",
      "1000:\tlearn: 3760.1454856\ttest: 4020.7740740\tbest: 4020.7740740 (1000)\ttotal: 56.7s\tremaining: 56.6s\n",
      "1250:\tlearn: 3275.7933501\ttest: 3545.6295993\tbest: 3545.6295993 (1250)\ttotal: 1m 11s\tremaining: 42.7s\n",
      "1250:\tlearn: 3275.7933501\ttest: 3545.6295993\tbest: 3545.6295993 (1250)\ttotal: 1m 11s\tremaining: 42.7s\n",
      "1500:\tlearn: 2913.0401878\ttest: 3193.0624357\tbest: 3193.0624357 (1500)\ttotal: 1m 25s\tremaining: 28.5s\n",
      "1500:\tlearn: 2913.0401878\ttest: 3193.0624357\tbest: 3193.0624357 (1500)\ttotal: 1m 25s\tremaining: 28.5s\n",
      "1750:\tlearn: 2612.7824269\ttest: 2900.4104210\tbest: 2900.4104210 (1750)\ttotal: 1m 39s\tremaining: 14.2s\n",
      "1750:\tlearn: 2612.7824269\ttest: 2900.4104210\tbest: 2900.4104210 (1750)\ttotal: 1m 39s\tremaining: 14.2s\n",
      "1999:\tlearn: 2357.5240286\ttest: 2650.6326127\tbest: 2650.6326127 (1999)\ttotal: 1m 54s\tremaining: 0us\n",
      "bestTest = 2650.632613\n",
      "bestIteration = 1999\n",
      "Fold 2 RMSE: 2650.6328\n",
      "1999:\tlearn: 2357.5240286\ttest: 2650.6326127\tbest: 2650.6326127 (1999)\ttotal: 1m 54s\tremaining: 0us\n",
      "bestTest = 2650.632613\n",
      "bestIteration = 1999\n",
      "Fold 2 RMSE: 2650.6328\n",
      "0:\tlearn: 34018.3223967\ttest: 34396.0740736\tbest: 34396.0740736 (0)\ttotal: 50.5ms\tremaining: 1m 40s\n",
      "0:\tlearn: 34018.3223967\ttest: 34396.0740736\tbest: 34396.0740736 (0)\ttotal: 50.5ms\tremaining: 1m 40s\n",
      "250:\tlearn: 6997.3200985\ttest: 7017.7289928\tbest: 7017.7289928 (250)\ttotal: 14.1s\tremaining: 1m 38s\n",
      "250:\tlearn: 6997.3200985\ttest: 7017.7289928\tbest: 7017.7289928 (250)\ttotal: 14.1s\tremaining: 1m 38s\n",
      "500:\tlearn: 5321.4079794\ttest: 5432.6040026\tbest: 5432.6040026 (500)\ttotal: 28.1s\tremaining: 1m 23s\n",
      "500:\tlearn: 5321.4079794\ttest: 5432.6040026\tbest: 5432.6040026 (500)\ttotal: 28.1s\tremaining: 1m 23s\n",
      "750:\tlearn: 4380.8750348\ttest: 4545.6265743\tbest: 4545.6265743 (750)\ttotal: 42.2s\tremaining: 1m 10s\n",
      "750:\tlearn: 4380.8750348\ttest: 4545.6265743\tbest: 4545.6265743 (750)\ttotal: 42.2s\tremaining: 1m 10s\n",
      "1000:\tlearn: 3726.6923536\ttest: 3918.1341668\tbest: 3918.1341668 (1000)\ttotal: 56.3s\tremaining: 56.2s\n",
      "1000:\tlearn: 3726.6923536\ttest: 3918.1341668\tbest: 3918.1341668 (1000)\ttotal: 56.3s\tremaining: 56.2s\n",
      "1250:\tlearn: 3239.3460236\ttest: 3449.8870488\tbest: 3449.8870488 (1250)\ttotal: 1m 10s\tremaining: 42.1s\n",
      "1250:\tlearn: 3239.3460236\ttest: 3449.8870488\tbest: 3449.8870488 (1250)\ttotal: 1m 10s\tremaining: 42.1s\n",
      "1500:\tlearn: 2862.0560814\ttest: 3087.1126763\tbest: 3087.1126763 (1500)\ttotal: 1m 24s\tremaining: 28.1s\n",
      "1500:\tlearn: 2862.0560814\ttest: 3087.1126763\tbest: 3087.1126763 (1500)\ttotal: 1m 24s\tremaining: 28.1s\n",
      "1750:\tlearn: 2554.8588777\ttest: 2790.0254859\tbest: 2790.0254859 (1750)\ttotal: 1m 38s\tremaining: 14s\n",
      "1750:\tlearn: 2554.8588777\ttest: 2790.0254859\tbest: 2790.0254859 (1750)\ttotal: 1m 38s\tremaining: 14s\n",
      "1999:\tlearn: 2301.2811609\ttest: 2542.5547822\tbest: 2542.5547822 (1999)\ttotal: 1m 52s\tremaining: 0us\n",
      "bestTest = 2542.554782\n",
      "bestIteration = 1999\n",
      "Fold 3 RMSE: 2542.5547\n",
      "1999:\tlearn: 2301.2811609\ttest: 2542.5547822\tbest: 2542.5547822 (1999)\ttotal: 1m 52s\tremaining: 0us\n",
      "bestTest = 2542.554782\n",
      "bestIteration = 1999\n",
      "Fold 3 RMSE: 2542.5547\n",
      "0:\tlearn: 34116.8213208\ttest: 33980.7110534\tbest: 33980.7110534 (0)\ttotal: 46ms\tremaining: 1m 32s\n",
      "0:\tlearn: 34116.8213208\ttest: 33980.7110534\tbest: 33980.7110534 (0)\ttotal: 46ms\tremaining: 1m 32s\n",
      "250:\tlearn: 6982.6648597\ttest: 7111.3358616\tbest: 7111.3358616 (250)\ttotal: 14.1s\tremaining: 1m 38s\n",
      "250:\tlearn: 6982.6648597\ttest: 7111.3358616\tbest: 7111.3358616 (250)\ttotal: 14.1s\tremaining: 1m 38s\n",
      "500:\tlearn: 5319.4543088\ttest: 5499.5802550\tbest: 5499.5802550 (500)\ttotal: 28.4s\tremaining: 1m 24s\n",
      "500:\tlearn: 5319.4543088\ttest: 5499.5802550\tbest: 5499.5802550 (500)\ttotal: 28.4s\tremaining: 1m 24s\n",
      "750:\tlearn: 4394.7032318\ttest: 4616.3980997\tbest: 4616.3980997 (750)\ttotal: 42.5s\tremaining: 1m 10s\n",
      "750:\tlearn: 4394.7032318\ttest: 4616.3980997\tbest: 4616.3980997 (750)\ttotal: 42.5s\tremaining: 1m 10s\n",
      "1000:\tlearn: 3742.0411714\ttest: 4000.4947040\tbest: 4000.4947040 (1000)\ttotal: 56.6s\tremaining: 56.5s\n",
      "1000:\tlearn: 3742.0411714\ttest: 4000.4947040\tbest: 4000.4947040 (1000)\ttotal: 56.6s\tremaining: 56.5s\n",
      "1250:\tlearn: 3271.2598391\ttest: 3551.4548593\tbest: 3551.4548593 (1250)\ttotal: 1m 10s\tremaining: 42.3s\n",
      "1250:\tlearn: 3271.2598391\ttest: 3551.4548593\tbest: 3551.4548593 (1250)\ttotal: 1m 10s\tremaining: 42.3s\n",
      "1500:\tlearn: 2893.8413540\ttest: 3190.9644115\tbest: 3190.9644115 (1500)\ttotal: 1m 24s\tremaining: 28.2s\n",
      "1500:\tlearn: 2893.8413540\ttest: 3190.9644115\tbest: 3190.9644115 (1500)\ttotal: 1m 24s\tremaining: 28.2s\n",
      "1750:\tlearn: 2589.2366663\ttest: 2896.7777757\tbest: 2896.7777757 (1750)\ttotal: 1m 38s\tremaining: 14.1s\n",
      "1750:\tlearn: 2589.2366663\ttest: 2896.7777757\tbest: 2896.7777757 (1750)\ttotal: 1m 38s\tremaining: 14.1s\n",
      "1999:\tlearn: 2323.9388801\ttest: 2638.9384393\tbest: 2638.9384393 (1999)\ttotal: 1m 52s\tremaining: 0us\n",
      "bestTest = 2638.938439\n",
      "bestIteration = 1999\n",
      "Fold 4 RMSE: 2638.9398\n",
      "1999:\tlearn: 2323.9388801\ttest: 2638.9384393\tbest: 2638.9384393 (1999)\ttotal: 1m 52s\tremaining: 0us\n",
      "bestTest = 2638.938439\n",
      "bestIteration = 1999\n",
      "Fold 4 RMSE: 2638.9398\n",
      "0:\tlearn: 34111.1507362\ttest: 34029.9807700\tbest: 34029.9807700 (0)\ttotal: 44.7ms\tremaining: 1m 29s\n",
      "0:\tlearn: 34111.1507362\ttest: 34029.9807700\tbest: 34029.9807700 (0)\ttotal: 44.7ms\tremaining: 1m 29s\n",
      "250:\tlearn: 6992.2156402\ttest: 7095.3564803\tbest: 7095.3564803 (250)\ttotal: 13.7s\tremaining: 1m 35s\n",
      "250:\tlearn: 6992.2156402\ttest: 7095.3564803\tbest: 7095.3564803 (250)\ttotal: 13.7s\tremaining: 1m 35s\n",
      "500:\tlearn: 5275.4975024\ttest: 5468.5546915\tbest: 5468.5546915 (500)\ttotal: 27.8s\tremaining: 1m 23s\n",
      "500:\tlearn: 5275.4975024\ttest: 5468.5546915\tbest: 5468.5546915 (500)\ttotal: 27.8s\tremaining: 1m 23s\n",
      "750:\tlearn: 4374.9500376\ttest: 4601.3463615\tbest: 4601.3463615 (750)\ttotal: 41.9s\tremaining: 1m 9s\n",
      "750:\tlearn: 4374.9500376\ttest: 4601.3463615\tbest: 4601.3463615 (750)\ttotal: 41.9s\tremaining: 1m 9s\n",
      "1000:\tlearn: 3731.3721769\ttest: 3983.2816885\tbest: 3983.2816885 (1000)\ttotal: 56.1s\tremaining: 56s\n",
      "1000:\tlearn: 3731.3721769\ttest: 3983.2816885\tbest: 3983.2816885 (1000)\ttotal: 56.1s\tremaining: 56s\n",
      "1250:\tlearn: 3252.2203890\ttest: 3525.5173493\tbest: 3525.5173493 (1250)\ttotal: 1m 10s\tremaining: 42s\n",
      "1250:\tlearn: 3252.2203890\ttest: 3525.5173493\tbest: 3525.5173493 (1250)\ttotal: 1m 10s\tremaining: 42s\n",
      "1500:\tlearn: 2878.0097825\ttest: 3163.0413680\tbest: 3163.0413680 (1500)\ttotal: 1m 24s\tremaining: 28s\n",
      "1500:\tlearn: 2878.0097825\ttest: 3163.0413680\tbest: 3163.0413680 (1500)\ttotal: 1m 24s\tremaining: 28s\n",
      "1750:\tlearn: 2576.0181058\ttest: 2867.4655295\tbest: 2867.4655295 (1750)\ttotal: 1m 38s\tremaining: 14s\n",
      "1750:\tlearn: 2576.0181058\ttest: 2867.4655295\tbest: 2867.4655295 (1750)\ttotal: 1m 38s\tremaining: 14s\n",
      "1999:\tlearn: 2324.0433448\ttest: 2621.1385888\tbest: 2621.1385888 (1999)\ttotal: 1m 52s\tremaining: 0us\n",
      "bestTest = 2621.138589\n",
      "bestIteration = 1999\n",
      "Fold 5 RMSE: 2621.1382\n",
      "1999:\tlearn: 2324.0433448\ttest: 2621.1385888\tbest: 2621.1385888 (1999)\ttotal: 1m 52s\tremaining: 0us\n",
      "bestTest = 2621.138589\n",
      "bestIteration = 1999\n",
      "Fold 5 RMSE: 2621.1382\n",
      "OOF RMSE: 2627.1241\n",
      "Bias correction factor: 1.0002\n",
      "Submission saved to: submissions\\submission_catboost_cv_2627.124.csv\n",
      "OOF RMSE: 2627.1241\n",
      "Bias correction factor: 1.0002\n",
      "Submission saved to: submissions\\submission_catboost_cv_2627.124.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>stores_times_sizes</td>\n",
       "      <td>16.334147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lifecycle_days</td>\n",
       "      <td>10.207004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>log_num_stores</td>\n",
       "      <td>10.135195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>price</td>\n",
       "      <td>6.156484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>log_lifecycle_days</td>\n",
       "      <td>6.055877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>weekly_sales</td>\n",
       "      <td>4.414806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>life_cycle_length</td>\n",
       "      <td>3.055617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>stores_per_size</td>\n",
       "      <td>2.853485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>num_stores</td>\n",
       "      <td>2.679184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>aggregated_family</td>\n",
       "      <td>2.396523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>lifecycle_weeks</td>\n",
       "      <td>1.633797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>fabric</td>\n",
       "      <td>1.249401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>img_pca_3</td>\n",
       "      <td>1.157581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>phase_in_dayofyear_sin</td>\n",
       "      <td>1.145913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>archetype_freq</td>\n",
       "      <td>1.145386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>phase_out_freq</td>\n",
       "      <td>0.986242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>img_pca_5</td>\n",
       "      <td>0.965383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>weekly_demand</td>\n",
       "      <td>0.886280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>phase_out_week</td>\n",
       "      <td>0.870655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>img_pca_7</td>\n",
       "      <td>0.842448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>img_emb_max</td>\n",
       "      <td>0.811071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>img_emb_min</td>\n",
       "      <td>0.766790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>color_mean</td>\n",
       "      <td>0.708718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>fabric_freq</td>\n",
       "      <td>0.681505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>color_name_freq</td>\n",
       "      <td>0.665197</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   feature  importance\n",
       "0       stores_times_sizes   16.334147\n",
       "1           lifecycle_days   10.207004\n",
       "2           log_num_stores   10.135195\n",
       "3                    price    6.156484\n",
       "4       log_lifecycle_days    6.055877\n",
       "5             weekly_sales    4.414806\n",
       "6        life_cycle_length    3.055617\n",
       "7          stores_per_size    2.853485\n",
       "8               num_stores    2.679184\n",
       "9        aggregated_family    2.396523\n",
       "10         lifecycle_weeks    1.633797\n",
       "11                  fabric    1.249401\n",
       "12               img_pca_3    1.157581\n",
       "13  phase_in_dayofyear_sin    1.145913\n",
       "14          archetype_freq    1.145386\n",
       "15          phase_out_freq    0.986242\n",
       "16               img_pca_5    0.965383\n",
       "17           weekly_demand    0.886280\n",
       "18          phase_out_week    0.870655\n",
       "19               img_pca_7    0.842448\n",
       "20             img_emb_max    0.811071\n",
       "21             img_emb_min    0.766790\n",
       "22              color_mean    0.708718\n",
       "23             fabric_freq    0.681505\n",
       "24         color_name_freq    0.665197"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross-validated CatBoost training and calibrated inference\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "oof_predictions = np.zeros(len(X))\n",
    "test_predictions = np.zeros(len(test_features))\n",
    "feature_importance = np.zeros(len(X.columns))\n",
    "\n",
    "catboost_base_params = dict(\n",
    "    iterations=2000,\n",
    "    depth=8,\n",
    "    learning_rate=0.025,\n",
    "    loss_function=\"RMSE\",\n",
    "    eval_metric=\"RMSE\",\n",
    "    l2_leaf_reg=6.0,\n",
    "    min_child_samples=25,\n",
    "    random_strength=0.4,\n",
    "    bagging_temperature=0.75,\n",
    "    od_type=\"Iter\",\n",
    "    od_wait=200,\n",
    "    verbose=250,\n",
    ")\n",
    "\n",
    "if CATBOOST_TASK_TYPE == \"GPU\":\n",
    "    catboost_base_params.update(\n",
    "        task_type=\"GPU\",\n",
    "        devices=GPU_DEVICES,\n",
    "        grow_policy=\"SymmetricTree\",\n",
    "        bootstrap_type=\"Bayesian\",\n",
    "        leaf_estimation_backtracking=\"AnyImprovement\",\n",
    "    )\n",
    "else:\n",
    "    catboost_base_params.update(\n",
    "        grow_policy=\"Lossguide\",\n",
    "        subsample=0.85,\n",
    "        colsample_bylevel=0.85,\n",
    "    )\n",
    "\n",
    "for fold, (train_idx, valid_idx) in enumerate(kf.split(X), start=1):\n",
    "    X_train_fold, X_valid_fold = X.iloc[train_idx], X.iloc[valid_idx]\n",
    "    y_train_fold, y_valid_fold = y.iloc[train_idx], y.iloc[valid_idx]\n",
    "\n",
    "    train_pool = Pool(X_train_fold, y_train_fold, cat_features=cat_features_for_pool)\n",
    "    valid_pool = Pool(X_valid_fold, y_valid_fold, cat_features=cat_features_for_pool)\n",
    "\n",
    "    model_params = catboost_base_params.copy()\n",
    "    model_params[\"random_seed\"] = SEED + fold\n",
    "    if CATBOOST_TASK_TYPE == \"GPU\":\n",
    "        model_params.pop(\"subsample\", None)\n",
    "        model_params.pop(\"colsample_bylevel\", None)\n",
    "    model = CatBoostRegressor(**model_params)\n",
    "    model.fit(train_pool, eval_set=valid_pool, use_best_model=True)\n",
    "\n",
    "    fold_oof = model.predict(valid_pool)\n",
    "    oof_predictions[valid_idx] = fold_oof\n",
    "    fold_rmse = root_mean_squared_error(y_valid_fold, fold_oof)\n",
    "    print(f\"Fold {fold} RMSE: {fold_rmse:.4f}\")\n",
    "\n",
    "    test_predictions += model.predict(Pool(test_features, cat_features=cat_features_for_pool)) / kf.n_splits\n",
    "    feature_importance += model.get_feature_importance(type=\"FeatureImportance\")\n",
    "\n",
    "cv_rmse = root_mean_squared_error(y, oof_predictions)\n",
    "bias_correction = y.mean() / oof_predictions.mean()\n",
    "test_predictions = np.clip(test_predictions * bias_correction, 0, None)\n",
    "\n",
    "submission_df = pd.DataFrame({\n",
    "    \"ID\": test_ids.values,\n",
    "    \"Production\": np.rint(test_predictions).astype(int)\n",
    "})\n",
    "submission_path = SUBMISSION_DIR / f\"submission_catboost_cv_{cv_rmse:.3f}.csv\"\n",
    "submission_df.to_csv(submission_path, index=False)\n",
    "\n",
    "feature_importance_df = (\n",
    "    pd.DataFrame({\"feature\": X.columns, \"importance\": feature_importance / kf.n_splits})\n",
    "    .sort_values(\"importance\", ascending=False)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "print(f\"OOF RMSE: {cv_rmse:.4f}\")\n",
    "print(f\"Bias correction factor: {bias_correction:.4f}\")\n",
    "print(f\"Submission saved to: {submission_path}\")\n",
    "feature_importance_df.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065d8e35",
   "metadata": {},
   "source": [
    "## GPU runtime notes\n",
    "- CatBoost now auto-detects CUDA availability and swaps to `task_type=\"GPU\"` on device `0` (tweak `GPU_DEVICES` near the top if you need a different card or multi-GPU string like `\"0-1\"`).\n",
    "- Numeric matrices are downcast to `float32` before reaching CatBoost so that GPU memory is used efficiently and host-to-device copies stay small.\n",
    "- If `get_gpu_device_count()` returns `0`, training silently falls back to CPU so the notebook still runs on machines without CUDA.\n",
    "- Make sure the NVIDIA driver and CUDA toolkit that ships with CatBoost (>=1.2) are installed—`pip install catboost` already bundles the necessary CUDA runtime for Windows 11/RTX 3060 setups."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
